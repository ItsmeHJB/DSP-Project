 # DSP Project - Harrison Bennion
 ##Python Interpreter
Python interpreter version: **Python 3.8.5**

To install the modules using pip:

`pip install -r requirements`

##C++ Compiler
EyeTrackerCode was compiled using Visual Studio 2019's compiler: **C/C++ Optimizing Compiler Version 19.28.29333 for x64**

Within EyeTrackerCode/.vscode/ directory, there are VS Code files to complete these tasks.
Inside of launch.json, the miDebuggerPath may require updating for other windows computer.

The executable main.exe will likely not work on other operating systems and should re-compiled using a local compiler.

## Script file
The script.cmd file is a simple script which runs the python using a local python venv. 

This currently points to my local venv, but you can update this depending on usage.

After stating ActiVAte, it waits 10 seconds for set up before opening the local host page on a browser.

##ActiVAte
A fork of the code by Legg *et al.* (2019).

Link: [activate](https://gitlab.uwe.ac.uk/pa-legg/activate)

Run activate_app.py to start the server, a link should print out after set up to allow for the ActiVAte to be opened with ease.

Once finished please press the **shutdown server** button in the bottom left of the page to prevent hanging executables.

If the eye tracking executable does not run on your PC, this will likely cause errors and can be commented out in both the index and shutdown functions under the variable called *tracker*.

During labelling, the labels and confidence scores will be recorded to file for use by the GazemapGen tool.

###Changing dataset
In order to change the dataset here, code will need to be changed in a few key places.
1. activate_config.py
    1. Within the *Options* module, updated the train_images, train_labels, test_images and test_labels variables.
    2. On top of this, if the number of classes has changed, the **number_of_classes** varaible should be updated
    3. Update the image directory names of the test and train images. The images are updated below.
2. image_downloader.py - Update dataset and folder/file structure, run program.
3. activate_app.py - Update file name and location to reflect where the new dataset images are located for the server
4. classifier_view_v4.js
    1. Update category labels inside of var 'labels'.
    2. Update image file directory in var train_dir
5. scatter_view_v3.js - Update the image source in a number of places

## ConfidenceCNN
This tool is the Convolutional Neural Network which is designed to train using gazemap produced by the 
GazemapGen tool to predict where a gazemap is deemed as confident or not using a binary scale.

This is currently just a binary predictor, but could be updated to work with continuous values.

## EyeTrackerCode
main.cpp is a C++ file which uses the interaction library provided by Tobii to interact with their eye tracker 4C.

During compilation, the include directory and the library path will need to be linked

The code will start and wait on a file which is generated by ActiVAte, so it won't work on it's own without edit.

Outputs a gaze data file which is used then deleted by the GazemapGen

The screen size for the eye tracker will needed to be updated to reflect the system it is running on.
Furthermore, editing the columns and rows value will change the granularity of the eye tracker interaction areas.

## GazemapGen
Uses the gaze data alsong side the confidence data to produce gazemaps which are distributed between a testing and training folders

The current distrubuiton is a simple 80//20.

